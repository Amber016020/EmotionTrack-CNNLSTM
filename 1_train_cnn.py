import os
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.applications import Xception
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

# --- åŸºæœ¬åƒæ•¸è¨­å®š ---
img_size = (96, 96)
batch_size = 16
epochs_pretrain = 30
epochs_finetune = 30

# --- è³‡æ–™è·¯å¾‘è¨­å®š ---
affectnet_path = r'D:\emotionRecognition\Face\EmotionTrack-CNNLSTM\data\train\AffectNet'
fer_path = r'D:\emotionRecognition\Face\EmotionTrack-CNNLSTM\data\train\FER-2013\train'

# è‡ªå‹•åµæ¸¬é¡åˆ¥æ•¸
num_classes = len(os.listdir(affectnet_path))

# --- AffectNet é è™•ç†å™¨èˆ‡è¼‰å…¥å™¨ ---
affectnet_gen = ImageDataGenerator(rescale=1./255, validation_split=0.1)

affectnet_train = affectnet_gen.flow_from_directory(
    affectnet_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

affectnet_val = affectnet_gen.flow_from_directory(
    affectnet_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

# --- EarlyStopping è¨­å®š ---
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# --- å»ºç«‹ Xception æ¨¡å‹ï¼ˆä½¿ç”¨ ImageNet é è¨“ç·´æ¬Šé‡ï¼‰---
base_model = Xception(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation='relu')(x)
predictions = Dense(num_classes, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

print("ğŸ“Œ é–‹å§‹åœ¨ AffectNet é è¨“ç·´ Xception ...")
history_pretrain = model.fit(
    affectnet_train,
    validation_data=affectnet_val,
    epochs=epochs_pretrain,
    callbacks=[early_stop]
)
model.save('xception_affectnet_pretrained.h5')

# --- é‡æ–°è¼‰å…¥ FER2013 ä¸¦æ›´æ–°é¡åˆ¥æ•¸ ---
num_classes_fer = len(os.listdir(fer_path))

# é‡æ–°å»ºç«‹æ¨¡å‹ï¼ˆè¼¸å‡ºå±¤ç‚º 7 é¡ï¼‰ä¹Ÿä¿ç•™ ImageNet é è¨“ç·´
base_model_finetune = Xception(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))
x = GlobalAveragePooling2D()(base_model_finetune.output)
x = Dense(256, activation='relu')(x)
predictions = Dense(num_classes_fer, activation='softmax')(x)
model_finetune = Model(inputs=base_model_finetune.input, outputs=predictions)

# è¼‰å…¥ AffectNet é è¨“ç·´å¥½çš„å·ç©å±¤æ¬Šé‡ï¼ˆå‰é¢å¹¾å±¤ï¼‰
for i in range(len(base_model_finetune.layers)):
    try:
        model_finetune.layers[i].set_weights(model.layers[i].get_weights())
    except:
        print(f"âš ï¸ è·³éç¬¬ {i} å±¤æ¬Šé‡ï¼ˆä¸ç›¸å®¹ï¼‰")

model_finetune.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# --- FER2013 è¼‰å…¥å™¨ ---
fer_gen = ImageDataGenerator(rescale=1./255, validation_split=0.1)

fer_train = fer_gen.flow_from_directory(
    fer_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    color_mode='rgb',
    subset='training'
)

fer_val = fer_gen.flow_from_directory(
    fer_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    color_mode='rgb',
    subset='validation'
)

print("ğŸ“Œ é–‹å§‹åœ¨ FER-2013 å¾®èª¿ Xception ...")
history_finetune = model_finetune.fit(
    fer_train,
    validation_data=fer_val,
    epochs=epochs_finetune,
    callbacks=[early_stop]
)
model_finetune.save('xception_finetuned_fer2013.h5')

# --- è¦–è¦ºåŒ–è¨“ç·´çµæœï¼ˆåˆ†é–‹ç•«ï¼‰---
plt.figure(figsize=(10, 8))

# ç¬¬ä¸€å¼µåœ–ï¼šAffectNet
plt.subplot(2, 1, 1)
plt.plot(history_pretrain.history['accuracy'], label='AffectNet Train Acc')
plt.plot(history_pretrain.history['val_accuracy'], label='AffectNet Val Acc')
plt.plot(history_pretrain.history['loss'], label='AffectNet Train Loss')
plt.plot(history_pretrain.history['val_loss'], label='AffectNet Val Loss')
plt.title('AffectNet Training History')
plt.xlabel('Epoch')
plt.ylabel('Accuracy / Loss')
plt.legend()
plt.grid(True)

# ç¬¬äºŒå¼µåœ–ï¼šFER2013
plt.subplot(2, 1, 2)
plt.plot(history_finetune.history['accuracy'], label='FER2013 Train Acc')
plt.plot(history_finetune.history['val_accuracy'], label='FER2013 Val Acc')
plt.plot(history_finetune.history['loss'], label='FER2013 Train Loss')
plt.plot(history_finetune.history['val_loss'], label='FER2013 Val Loss')
plt.title('FER2013 Fine-Tuning History')
plt.xlabel('Epoch')
plt.ylabel('Accuracy / Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.savefig("CNN_training_plot_split.png", dpi=300)
plt.show()
